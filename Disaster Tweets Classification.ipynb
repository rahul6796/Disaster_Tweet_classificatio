{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from contractions import contractions_dict\n",
    "from pattern.en import tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Morgantown, WV</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword        location  \\\n",
       "0   0  ablaze             NaN   \n",
       "1   1  ablaze             NaN   \n",
       "2   2  ablaze   New York City   \n",
       "3   3  ablaze  Morgantown, WV   \n",
       "4   4  ablaze             NaN   \n",
       "\n",
       "                                                text  target  \n",
       "0  Communal violence in Bhainsa, Telangana. \"Ston...       1  \n",
       "1  Telangana: Section 144 has been imposed in Bha...       1  \n",
       "2  Arsonist sets cars ablaze at dealership https:...       1  \n",
       "3  Arsonist sets cars ablaze at dealership https:...       1  \n",
       "4  \"Lord Jesus, your love brings freedom and pard...       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['keyword','location','id'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Communal violence in Bhainsa, Telangana. \"Ston...       1\n",
       "1  Telangana: Section 144 has been imposed in Bha...       1\n",
       "2  Arsonist sets cars ablaze at dealership https:...       1\n",
       "3  Arsonist sets cars ablaze at dealership https:...       1\n",
       "4  \"Lord Jesus, your love brings freedom and pard...       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11365</th>\n",
       "      <td>Media should have warned us well in advance. T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11366</th>\n",
       "      <td>i feel directly attacked ðŸ’€ i consider moonbin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11367</th>\n",
       "      <td>i feel directly attacked ðŸ’€ i consider moonbin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11368</th>\n",
       "      <td>ok who remember \"outcast\" nd the \"dora\" au?? T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11369</th>\n",
       "      <td>Jake Corway wrecked while running 14th at IRP.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "11365  Media should have warned us well in advance. T...       0\n",
       "11366  i feel directly attacked ðŸ’€ i consider moonbin ...       0\n",
       "11367  i feel directly attacked ðŸ’€ i consider moonbin ...       0\n",
       "11368  ok who remember \"outcast\" nd the \"dora\" au?? T...       0\n",
       "11369     Jake Corway wrecked while running 14th at IRP.       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the thing that has infuriated me. If Black Democrats were paying freaking attention, it should have infuriated tâ€¦'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][4446]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removed_url(text):\n",
    "    \"\"\"function for removed url\"\"\"\n",
    "    url_pattern = re.compile(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*')\n",
    "    filtered_text = re.sub(url_pattern,'',text)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_url_text = data['text'].apply(lambda x : removed_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I became lost in a Himalayan blizzard at 4000 meters and was saved by a horse. '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_url_text[1111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removed_html(text):\n",
    "    \"\"\"function for removed html\"\"\"\n",
    "    html_pattern = re.compile(r'<.*?>')\n",
    "    filtered_text = re.sub(html_pattern,'',text)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_html_text = removed_url_text.apply(lambda x : removed_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We continue to update our 30-day aftershock forecast scenarios for #PuertoRico. Forecasts are posted in both English â€¦'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_html_text[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removed_unwanted_characters(text):\n",
    "    \"\"\"function for removing forward_slash_followed_by_string between the text\"\"\"\n",
    "    backslash_pattern = re.compile(r'(\\r)+(\\n)*(\\r)+(\\n)*($)(\\w)+|(\\r)+(\\n)*(\\r)+(\\n)*(#)(\\w)+|(#)(\\w)+|(&)(\\w)+|(@)(\\w)+|($)(\\w)+|[?/(\\r)+(\\n)*(#)*(_)*(\\d)+]+')\n",
    "    filtered_text = re.sub(backslash_pattern,' ', text)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_unwanted_characters_text = removed_html_text.apply(lambda x : removed_unwanted_characters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We continue to update our  -day aftershock forecast scenarios for  . Forecasts are posted in both English â€¦'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_unwanted_characters_text[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_text(text):\n",
    "    \"\"\"function for tokenized tweets text\"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contraction(text,contractions_dict):\n",
    "    \"\"\"function for removed the contraction words\"\"\"\n",
    "    contraction_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),\n",
    "                                    flags = re.IGNORECASE|re.DOTALL)\n",
    "    \"\"\"function for expand match\"\"\"\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expand_contraction = contractions_dict.get(match) if contractions_dict.get(match) else contractions_dict.get(match.lower())\n",
    "        \n",
    "        #expanded_contraction = first_char + contraction[1:]\n",
    "        return expand_contraction\n",
    "    \n",
    "    expanded_text = contraction_pattern.sub(expand_match,text)\n",
    "    expanded_text = re.sub(\"'\",\"\",expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_contraction_text = removed_unwanted_characters_text.apply(lambda x : expand_contraction(x,contractions_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We continue to update our  -day aftershock forecast scenarios for  . Forecasts are posted in both English â€¦'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contraction_text[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removed_special_characters(text):\n",
    "    \"\"\"function for removed special characters from the text\"\"\"\n",
    "    tokens = tokenized_text(text)\n",
    "    special_characters_pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    filter_tokens = filter(None,[special_characters_pattern.sub('',token) for token in tokens])\n",
    "    filtered_text = ' '.join(filter_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_special_characters_text = expand_contraction_text.apply(lambda x:removed_special_characters(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We continue to update our day aftershock forecast scenarios for Forecasts are posted in both English â€¦'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_special_characters_text[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removed_emoji(text):\n",
    "    \"\"\"Function for remove Emoji from the text\"\"\"\n",
    "    pattern = re.compile(r'[^\\u1F600-\\u1F6FF\\s]')\n",
    "    filtered_text = re.sub(pattern,'',text)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_emoji_text = removed_special_characters_text.apply(lambda x:removed_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We continue to update our day aftershock forecast scenarios for Forecasts are posted in both English '"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_emoji_text[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removed_unicode(text):\n",
    "    \"\"\"function for removed unicode from the text\"\"\"\n",
    "    unicode_pattern = re.compile(r'\\w+[^\\x00-\\x7F]\\w+|[^\\x00-\\x7F]')\n",
    "    filtered_text = re.sub(unicode_pattern,'',text)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_unicode_text = removed_emoji_text.apply(lambda x:removed_unicode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We continue to update our day aftershock forecast scenarios for Forecasts are posted in both English '"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_unicode_text[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removed_stopwords(text):\n",
    "    \"\"\"function for removed stopwords from the text\"\"\"\n",
    "    tokens = tokenized_text(text)\n",
    "    filtered_text = [token for token in tokens if token not in stopwords_list]\n",
    "    filtered_text = ' '.join(filtered_text)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_stopwords_text = removed_unicode_text.apply(lambda x:removed_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We continue update day aftershock forecast scenarios Forecasts posted English'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_stopwords_text[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removed_unwanted_string(text):\n",
    "    \"\"\"function for removed two lenght string from text\"\"\"\n",
    "    string_pattern = re.compile(r'\\b(\\w{1})\\b|\\b(\\w{2})\\b|\\b(\\w{3})\\b')\n",
    "    filered_text = re.sub(string_pattern,'',text)\n",
    "    return filered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_unwanted_string_text = removed_stopwords_text.apply(lambda x:removed_unwanted_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' continue update  aftershock forecast scenarios Forecasts posted English'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_unwanted_string_text[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Annotate text token with POS tags\"\"\"\n",
    "def pos_tag_text(text):\n",
    "    \"\"\"Convert Penn treebank tag to wordnet tag\"\"\"\n",
    "    def penn_to_wn_tags(pos_tag):\n",
    "        if pos_tag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "        elif pos_tag.startswith('V'):\n",
    "            return wn.VERB\n",
    "        elif pos_tag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "        elif pos_tag.startswith('R'):\n",
    "            return wn.ADV\n",
    "        else:\n",
    "            return wn.NOUN\n",
    "    tagged_text = tag(text)\n",
    "    tagged_lower_text = [(word.lower(),penn_to_wn_tags(pos_tag)) for word , pos_tag in tagged_text]\n",
    "    \n",
    "    return tagged_lower_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    \"\"\"function for lemmatize text based on POS tags\"\"\"\n",
    "    pos_tagged_text = pos_tag_text(text)\n",
    "    lemmatized_tokens = [wnl.lemmatize(word,pos_tag) if pos_tag else word for word , pos_tag in pos_tagged_text]\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_text = removed_unwanted_string_text.apply(lambda x:lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reality bend around chromatic form effortlessly float wreckage check retribution rhads'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_text[11322]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_set(text):\n",
    "    \"\"\"function for convert text to vocabulary \"\"\"\n",
    "    return set(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_set_text = lemmatized_text.apply(lambda x:convert_to_set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = list(convert_to_set_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for s in unique_words:\n",
    "    \n",
    "    vocab = vocab.union(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doityourself',\n",
       " 'brainless',\n",
       " 'babysitting',\n",
       " 'deepika',\n",
       " 'larry',\n",
       " 'toffler',\n",
       " 'virus',\n",
       " 'jaish',\n",
       " 'poten',\n",
       " 'gerard',\n",
       " 'loosely',\n",
       " 'unfollowing',\n",
       " 'yes',\n",
       " 'veles',\n",
       " 'getter',\n",
       " 'pernambuco',\n",
       " 'sanghi',\n",
       " 'nonaccidental',\n",
       " 'lapina',\n",
       " 'thrash',\n",
       " 'astagfirullah',\n",
       " 'peek',\n",
       " 'fang',\n",
       " 'cooker',\n",
       " 'bastard',\n",
       " 'ikonic',\n",
       " 'faryab',\n",
       " 'hack',\n",
       " 'pollen',\n",
       " 'hacker',\n",
       " 'eastbound',\n",
       " 'construct',\n",
       " 'mallam',\n",
       " 'expressway',\n",
       " 'partial',\n",
       " 'hanga',\n",
       " 'strang',\n",
       " 'muscular',\n",
       " 'alexander',\n",
       " 'steak',\n",
       " 'within',\n",
       " 'hapo',\n",
       " 'company',\n",
       " 'bridal',\n",
       " 'ogiggling',\n",
       " 'chavez',\n",
       " 'sauce',\n",
       " 'dread',\n",
       " 'diet',\n",
       " 'take',\n",
       " 'though',\n",
       " 'parac',\n",
       " 'schenker',\n",
       " 'antitrans',\n",
       " 'bailout',\n",
       " 'plate',\n",
       " 'serpentes',\n",
       " 'closer',\n",
       " 'appearing',\n",
       " 'weaponsyielding',\n",
       " 'recover',\n",
       " 'qasem',\n",
       " 'counselling',\n",
       " 'malignant',\n",
       " 'uptick',\n",
       " 'defective',\n",
       " 'graphqljit',\n",
       " 'limitless',\n",
       " 'aircraft',\n",
       " 'taehyungs',\n",
       " 'pste',\n",
       " 'ewan',\n",
       " 'unsaid',\n",
       " 'kaabi',\n",
       " 'nara',\n",
       " 'bigand',\n",
       " 'volted',\n",
       " 'valiasr',\n",
       " 'involvement',\n",
       " 'bag',\n",
       " 'coast',\n",
       " 'excrement',\n",
       " 'onthegr',\n",
       " 'evacuation',\n",
       " 'misaki',\n",
       " 'mouth',\n",
       " 'brilliant',\n",
       " 'whats',\n",
       " 'europa',\n",
       " 'tie',\n",
       " 'cyclist',\n",
       " 'netherlands',\n",
       " 'ideology',\n",
       " 'fuelled',\n",
       " 'tarot',\n",
       " 'attacked',\n",
       " 'fukushimas',\n",
       " 'woke',\n",
       " 'quid',\n",
       " 'counsel',\n",
       " 'susanoo',\n",
       " 'cerberus',\n",
       " 'hipsears',\n",
       " 'typehuman',\n",
       " 'faintly',\n",
       " 'socio',\n",
       " 'dinah',\n",
       " 'latter',\n",
       " 'ramsey',\n",
       " 'pelting',\n",
       " 'normality',\n",
       " 'burried',\n",
       " 'cane',\n",
       " 'resilience',\n",
       " 'wqow',\n",
       " 'scahill',\n",
       " 'raze',\n",
       " 'antrim',\n",
       " 'lite',\n",
       " 'pathankot',\n",
       " 'xtian',\n",
       " 'lady',\n",
       " 'weep',\n",
       " 'dismount',\n",
       " 'minago',\n",
       " 'waning',\n",
       " 'wanzhou',\n",
       " 'peer',\n",
       " 'nationalism',\n",
       " 'nerc',\n",
       " 'definitel',\n",
       " 'intercept',\n",
       " 'headi',\n",
       " 'reddishbrown',\n",
       " 'near',\n",
       " 'greenguy',\n",
       " 'pilipinos',\n",
       " 'education',\n",
       " 'supply',\n",
       " 'shakespearean',\n",
       " 'history',\n",
       " 'topsecret',\n",
       " 'russianmade',\n",
       " 'scuppered',\n",
       " 'tropical',\n",
       " 'penalty',\n",
       " 'woul',\n",
       " 'menstrual',\n",
       " 'humbly',\n",
       " 'neomccarthyism',\n",
       " 'westinghouse',\n",
       " 'mathematician',\n",
       " 'guess',\n",
       " 'inconvenience',\n",
       " 'kabir',\n",
       " 'album',\n",
       " 'singleuse',\n",
       " 'slime',\n",
       " 'successful',\n",
       " 'rediscovery',\n",
       " 'verb',\n",
       " 'itworks',\n",
       " 'lulu',\n",
       " 'fiscally',\n",
       " 'koala',\n",
       " 'cruciate',\n",
       " 'levy',\n",
       " 'listen',\n",
       " 'phenomenon',\n",
       " 'waaf',\n",
       " 'entropy',\n",
       " 'shorty',\n",
       " 'attest',\n",
       " 'unsettled',\n",
       " 'relaxed',\n",
       " 'tuesday',\n",
       " 'jerky',\n",
       " 'sydney',\n",
       " 'stalin',\n",
       " 'contin',\n",
       " 'civilisation',\n",
       " 'method',\n",
       " 'aired',\n",
       " 'protested',\n",
       " 'skip',\n",
       " 'eventually',\n",
       " 'dalila',\n",
       " 'sparky',\n",
       " 'tthe',\n",
       " 'sicken',\n",
       " 'international',\n",
       " 'combined',\n",
       " 'sipho',\n",
       " 'fiery',\n",
       " 'seismometers',\n",
       " 'alma',\n",
       " 'illconceived',\n",
       " 'kit',\n",
       " 'datang',\n",
       " 'flightless',\n",
       " 'maniac',\n",
       " 'vouge',\n",
       " 'unrelated',\n",
       " 'parenting',\n",
       " 'paris',\n",
       " 'bend',\n",
       " 'somebody',\n",
       " 'linger',\n",
       " 'victim',\n",
       " 'regularly',\n",
       " 'riot',\n",
       " 'carnage',\n",
       " 'natsu',\n",
       " 'cybernews',\n",
       " 'boy',\n",
       " 'maintain',\n",
       " 'authentic',\n",
       " 'apparent',\n",
       " 'scarred',\n",
       " 'committed',\n",
       " 'ccorn',\n",
       " 'temper',\n",
       " 'fleetwood',\n",
       " 'wideninghe',\n",
       " 'receiv',\n",
       " 'partake',\n",
       " 'inund',\n",
       " 'unity',\n",
       " 'noah',\n",
       " 'pee',\n",
       " 'jetsam',\n",
       " 'amelia',\n",
       " 'thankyou',\n",
       " 'kakinada',\n",
       " 'kangaroos',\n",
       " 'naija',\n",
       " 'natalie',\n",
       " 'assail',\n",
       " 'unlucky',\n",
       " 'ambulanc',\n",
       " 'binding',\n",
       " 'linen',\n",
       " 'surely',\n",
       " 'leftist',\n",
       " 'expulsion',\n",
       " 'allege',\n",
       " 'efficacy',\n",
       " 'cram',\n",
       " 'earpods',\n",
       " 'unexpected',\n",
       " 'limerick',\n",
       " 'dman',\n",
       " 'pine',\n",
       " 'son',\n",
       " 'dday',\n",
       " 'floo',\n",
       " 'hum',\n",
       " 'powah',\n",
       " 'intrus',\n",
       " 'heig',\n",
       " 'childish',\n",
       " 'aftermat',\n",
       " 'constrict',\n",
       " 'shaqiri',\n",
       " 'drive',\n",
       " 'murder',\n",
       " 'variety',\n",
       " 'manipulate',\n",
       " 'enjoyment',\n",
       " 'draft',\n",
       " 'scavenge',\n",
       " 'mend',\n",
       " 'dougga',\n",
       " 'diack',\n",
       " 'sent',\n",
       " 'badmouth',\n",
       " 'backpacker',\n",
       " 'rory',\n",
       " 'campaig',\n",
       " 'llamas',\n",
       " 'choplifter',\n",
       " 'bioflash',\n",
       " 'pejaba',\n",
       " 'cont',\n",
       " 'cleanness',\n",
       " 'isolated',\n",
       " 'shou',\n",
       " 'mental',\n",
       " 'utmost',\n",
       " 'lond',\n",
       " 'ceasar',\n",
       " 'lahore',\n",
       " 'tmzd',\n",
       " 'cake',\n",
       " 'instructed',\n",
       " 'satya',\n",
       " 'annihilation',\n",
       " 'governor',\n",
       " 'hopper',\n",
       " 'top',\n",
       " 'enormity',\n",
       " 'americas',\n",
       " 'using',\n",
       " 'google',\n",
       " 'pakistani',\n",
       " 'pipenger',\n",
       " 'infantry',\n",
       " 'salute',\n",
       " 'flanders',\n",
       " 'eyelid',\n",
       " 'spectacular',\n",
       " 'vocal',\n",
       " 'pressious',\n",
       " 'tray',\n",
       " 'woodg',\n",
       " 'ling',\n",
       " 'vain',\n",
       " 'shamble',\n",
       " 'zakir',\n",
       " 'lesbian',\n",
       " 'murde',\n",
       " 'network',\n",
       " 'anyplace',\n",
       " 'plaster',\n",
       " 'coac',\n",
       " 'wear',\n",
       " 'annoy',\n",
       " 'joyously',\n",
       " 'tourniquet',\n",
       " 'gush',\n",
       " 'speedy',\n",
       " 'sneer',\n",
       " 'guazi',\n",
       " 'politics',\n",
       " 'vest',\n",
       " 'dublin',\n",
       " 'para',\n",
       " 'mysteriously',\n",
       " 'abducted',\n",
       " 'bongino',\n",
       " 'self',\n",
       " 'horror',\n",
       " 'russell',\n",
       " 'rutherford',\n",
       " 'silver',\n",
       " 'storm',\n",
       " 'dayum',\n",
       " 'impression',\n",
       " 'dropped',\n",
       " 'shaft',\n",
       " 'dramatically',\n",
       " 'michigan',\n",
       " 'restrained',\n",
       " 'especial',\n",
       " 'khali',\n",
       " 'badg',\n",
       " 'oshey',\n",
       " 'appl',\n",
       " 'comparison',\n",
       " 'odds',\n",
       " 'mentorship',\n",
       " 'naruto',\n",
       " 'expressed',\n",
       " 'stature',\n",
       " 'darkness',\n",
       " 'sweeneys',\n",
       " 'taurus',\n",
       " 'dunn',\n",
       " 'nome',\n",
       " 'loneliness',\n",
       " 'razzle',\n",
       " 'lakini',\n",
       " 'dougl',\n",
       " 'freed',\n",
       " 'palace',\n",
       " 'kouyape',\n",
       " 'muhammad',\n",
       " 'sentenced',\n",
       " 'bother',\n",
       " 'session',\n",
       " 'cartwheel',\n",
       " 'kiribati',\n",
       " 'blindly',\n",
       " 'prestigious',\n",
       " 'foreground',\n",
       " 'meme',\n",
       " 'initially',\n",
       " 'lidocaine',\n",
       " 'wlbt',\n",
       " 'pregnancy',\n",
       " 'detector',\n",
       " 'double',\n",
       " 'kashmir',\n",
       " 'yoga',\n",
       " 'unlike',\n",
       " 'davis',\n",
       " 'abound',\n",
       " 'hotboxed',\n",
       " 'dishonest',\n",
       " 'buddhu',\n",
       " 'gareth',\n",
       " 'iskanderm',\n",
       " 'sparklin',\n",
       " 'denier',\n",
       " 'parasite',\n",
       " 'rarely',\n",
       " 'potato',\n",
       " 'dumbing',\n",
       " 'affair',\n",
       " 'generally',\n",
       " 'placement',\n",
       " 'flotsam',\n",
       " 'ignite',\n",
       " 'picknicks',\n",
       " 'circus',\n",
       " 'roadworks',\n",
       " 'feature',\n",
       " 'downstairs',\n",
       " 'nuclear',\n",
       " 'overtaking',\n",
       " 'effortlessly',\n",
       " 'conduct',\n",
       " 'sive',\n",
       " 'vaccine',\n",
       " 'welco',\n",
       " 'delete',\n",
       " 'nonfiction',\n",
       " 'findin',\n",
       " 'rabbit',\n",
       " 'farm',\n",
       " 'foreign',\n",
       " 'raccoon',\n",
       " 'mughals',\n",
       " 'ustad',\n",
       " 'fresher',\n",
       " 'twoyear',\n",
       " 'slob',\n",
       " 'wann',\n",
       " 'spontaneous',\n",
       " 'redhanded',\n",
       " 'sunk',\n",
       " 'message',\n",
       " 'controversy',\n",
       " 'touhou',\n",
       " 'shooter',\n",
       " 'autopsy',\n",
       " 'aside',\n",
       " 'visual',\n",
       " 'yajurveda',\n",
       " 'prevent',\n",
       " 'aim',\n",
       " 'neve',\n",
       " 'everest',\n",
       " 'nancy',\n",
       " 'kale',\n",
       " 'audiobook',\n",
       " 'hamilton',\n",
       " 'izai',\n",
       " 'slim',\n",
       " 'ventura',\n",
       " 'protect',\n",
       " 'terrorism',\n",
       " 'embarassment',\n",
       " 'sticky',\n",
       " 'falkirk',\n",
       " 'preorder',\n",
       " 'personalise',\n",
       " 'rockfest',\n",
       " 'herbert',\n",
       " 'penumbral',\n",
       " 'disa',\n",
       " 'bike',\n",
       " 'obviously',\n",
       " 'timeline',\n",
       " 'vegetabl',\n",
       " 'return',\n",
       " 'ballistic',\n",
       " 'stoke',\n",
       " 'imagine',\n",
       " 'salukis',\n",
       " 'gibson',\n",
       " 'arachnitcz',\n",
       " 'brickyard',\n",
       " 'assess',\n",
       " 'bulusan',\n",
       " 'linda',\n",
       " 'roller',\n",
       " 'pay',\n",
       " 'guarantee',\n",
       " 'scumo',\n",
       " 'maharashtra',\n",
       " 'ying',\n",
       " 'generosity',\n",
       " 'hayward',\n",
       " 'hind',\n",
       " 'rulership',\n",
       " 'missile',\n",
       " 'kidnapping',\n",
       " 'shibuya',\n",
       " 'moon',\n",
       " 'carrickfergus',\n",
       " 'foreclosure',\n",
       " 'hollow',\n",
       " 'mbye',\n",
       " 'hooked',\n",
       " 'constraint',\n",
       " 'fighter',\n",
       " 'bandwagon',\n",
       " 'swissquote',\n",
       " 'barking',\n",
       " 'gregor',\n",
       " 'woolworth',\n",
       " 'subordinate',\n",
       " 'wombats',\n",
       " 'jolt',\n",
       " 'pervert',\n",
       " 'visits',\n",
       " 'datdrop',\n",
       " 'parliament',\n",
       " 'stepped',\n",
       " 'subreddit',\n",
       " 'future',\n",
       " 'tugging',\n",
       " 'midst',\n",
       " 'danish',\n",
       " 'radley',\n",
       " 'revolve',\n",
       " 'newscorp',\n",
       " 'forg',\n",
       " 'retribution',\n",
       " 'atmos',\n",
       " 'mexico',\n",
       " 'meaning',\n",
       " 'jsoldirtybasement',\n",
       " 'cudgewa',\n",
       " 'iponing',\n",
       " 'trail',\n",
       " 'kellin',\n",
       " 'devin',\n",
       " 'timing',\n",
       " 'spending',\n",
       " 'aadharcard',\n",
       " 'ifrit',\n",
       " 'kubrick',\n",
       " 'nikkietutorials',\n",
       " 'tgiving',\n",
       " 'semienclosed',\n",
       " 'safeguard',\n",
       " 'notification',\n",
       " 'interrupted',\n",
       " 'jeffery',\n",
       " 'deed',\n",
       " 'goddess',\n",
       " 'adil',\n",
       " 'chancellor',\n",
       " 'approve',\n",
       " 'carter',\n",
       " 'yohan',\n",
       " 'shard',\n",
       " 'widow',\n",
       " 'crusty',\n",
       " 'brazilian',\n",
       " 'surebet',\n",
       " 'trenton',\n",
       " 'operation',\n",
       " 'everyday',\n",
       " 'malpractice',\n",
       " 'bombbomb',\n",
       " 'cop',\n",
       " 'gusu',\n",
       " 'expedition',\n",
       " 'inral',\n",
       " 'item',\n",
       " 'fatal',\n",
       " 'musharaf',\n",
       " 'aravalli',\n",
       " 'wrecka',\n",
       " 'sest',\n",
       " 'gyroscopic',\n",
       " 'danganronp',\n",
       " 'flood',\n",
       " 'summer',\n",
       " 'sends',\n",
       " 'djoko',\n",
       " 'cheese',\n",
       " 'manutd',\n",
       " 'campus',\n",
       " 'condescending',\n",
       " 'quell',\n",
       " 'abduct',\n",
       " 'blus',\n",
       " 'unarmed',\n",
       " 'complicate',\n",
       " 'parched',\n",
       " 'sukukaj',\n",
       " 'fjlkawefsa',\n",
       " 'during',\n",
       " 'northwest',\n",
       " 'detona',\n",
       " 'donald',\n",
       " 'anoth',\n",
       " 'calendar',\n",
       " 'inconvenient',\n",
       " 'spear',\n",
       " 'aight',\n",
       " 'gale',\n",
       " 'destroyed',\n",
       " 'exotic',\n",
       " 'chopra',\n",
       " 'neal',\n",
       " 'rwandan',\n",
       " 'stirrin',\n",
       " 'naples',\n",
       " 'burnley',\n",
       " 'french',\n",
       " 'dontent',\n",
       " 'wink',\n",
       " 'interesting',\n",
       " 'highwy',\n",
       " 'inroad',\n",
       " 'argue',\n",
       " 'yimet',\n",
       " 'antagonistic',\n",
       " 'pelosischumer',\n",
       " 'ramguha',\n",
       " 'vested',\n",
       " 'basketball',\n",
       " 'guidicelli',\n",
       " 'miri',\n",
       " 'cornucopia',\n",
       " 'ascot',\n",
       " 'gospel',\n",
       " 'succumbed',\n",
       " 'stanley',\n",
       " 'analyt',\n",
       " 'generate',\n",
       " 'gulag',\n",
       " 'worsen',\n",
       " 'succeed',\n",
       " 'austin',\n",
       " 'fort',\n",
       " 'randomly',\n",
       " 'fast',\n",
       " 'retire',\n",
       " 'archeological',\n",
       " 'bubby',\n",
       " 'tota',\n",
       " 'fave',\n",
       " 'metaphorically',\n",
       " 'sought',\n",
       " 'cash',\n",
       " 'beaufort',\n",
       " 'exert',\n",
       " 'boxing',\n",
       " 'studio',\n",
       " 'selfmanagement',\n",
       " 'writer',\n",
       " 'digging',\n",
       " 'healer',\n",
       " 'planned',\n",
       " 'inflict',\n",
       " 'fireground',\n",
       " 'gentle',\n",
       " 'materialize',\n",
       " 'prosper',\n",
       " 'kecheng',\n",
       " 'brutality',\n",
       " 'relation',\n",
       " 'pikin',\n",
       " 'mccormack',\n",
       " 'groupie',\n",
       " 'alleged',\n",
       " 'honour',\n",
       " 'edgewood',\n",
       " 'ordered',\n",
       " 'penn',\n",
       " 'hurricane',\n",
       " 'ignited',\n",
       " 'fedl',\n",
       " 'tackle',\n",
       " 'demonstrated',\n",
       " 'grayson',\n",
       " 'devastated',\n",
       " 'colossal',\n",
       " 'taffy',\n",
       " 'antibioterrorism',\n",
       " 'dime',\n",
       " 'fornication',\n",
       " 'somewhat',\n",
       " 'haya',\n",
       " 'unimaginable',\n",
       " 'meted',\n",
       " 'descendant',\n",
       " 'amphibi',\n",
       " 'anyone',\n",
       " 'spiritus',\n",
       " 'riggi',\n",
       " 'gaurav',\n",
       " 'yabo',\n",
       " 'cage',\n",
       " 'dolan',\n",
       " 'vbied',\n",
       " 'jerk',\n",
       " 'expense',\n",
       " 'lookout',\n",
       " 'youtuber',\n",
       " 'camper',\n",
       " 'rajapaksa',\n",
       " 'falcon',\n",
       " 'await',\n",
       " 'perth',\n",
       " 'polythene',\n",
       " 'selfserving',\n",
       " 'overboard',\n",
       " 'however',\n",
       " 'acupuncture',\n",
       " 'writte',\n",
       " 'elibya',\n",
       " 'fucknigga',\n",
       " 'desert',\n",
       " 'concerned',\n",
       " 'oake',\n",
       " 'adorable',\n",
       " 'character',\n",
       " 'irani',\n",
       " 'star',\n",
       " 'volume',\n",
       " 'right',\n",
       " 'huawei',\n",
       " 'bandh',\n",
       " 'democracy',\n",
       " 'tremor',\n",
       " 'netcare',\n",
       " 'bung',\n",
       " 'owne',\n",
       " 'growth',\n",
       " 'officials',\n",
       " 'deem',\n",
       " 'morrison',\n",
       " 'discrminate',\n",
       " 'armed',\n",
       " 'balm',\n",
       " 'plastic',\n",
       " 'brin',\n",
       " 'slave',\n",
       " 'dich',\n",
       " 'destro',\n",
       " 'longdead',\n",
       " 'wylin',\n",
       " 'louis',\n",
       " 'princess',\n",
       " 'windmill',\n",
       " 'closet',\n",
       " 'lover',\n",
       " 'snes',\n",
       " 'torrential',\n",
       " 'guiding',\n",
       " 'setting',\n",
       " 'fantastic',\n",
       " 'lived',\n",
       " 'pipeline',\n",
       " 'virtue',\n",
       " 'shdc',\n",
       " 'raavan',\n",
       " 'ecigarettes',\n",
       " 'australian',\n",
       " 'bachelor',\n",
       " 'electable',\n",
       " 'wharf',\n",
       " 'araphym',\n",
       " 'dingley',\n",
       " 'kochi',\n",
       " 'destroyer',\n",
       " 'treasure',\n",
       " 'hoomans',\n",
       " 'potentially',\n",
       " 'gwari',\n",
       " 'exiled',\n",
       " 'heroine',\n",
       " 'obsidian',\n",
       " 'handedly',\n",
       " 'deal',\n",
       " 'woodbury',\n",
       " 'demolishers',\n",
       " 'meursault',\n",
       " 'admission',\n",
       " 'shia',\n",
       " 'horseriding',\n",
       " 'eclipse',\n",
       " 'hate',\n",
       " 'fulton',\n",
       " 'obamas',\n",
       " 'tues',\n",
       " 'pest',\n",
       " 'bagga',\n",
       " 'turtle',\n",
       " 'subjectivity',\n",
       " 'raindrop',\n",
       " 'yob',\n",
       " 'distribute',\n",
       " 'spartacus',\n",
       " 'chronological',\n",
       " 'dioxide',\n",
       " 'stomachchurning',\n",
       " 'deadmau',\n",
       " 'lmaooo',\n",
       " 'twelve',\n",
       " 'thundercats',\n",
       " 'mist',\n",
       " 'gerwig',\n",
       " 'darimi',\n",
       " 'staticallygenerated',\n",
       " 'malmedy',\n",
       " 'vardhan',\n",
       " 'radiati',\n",
       " 'petal',\n",
       " 'kababayans',\n",
       " 'exceptionally',\n",
       " 'yeah',\n",
       " 'oxford',\n",
       " 'bashers',\n",
       " 'skskskks',\n",
       " 'investor',\n",
       " 'injurie',\n",
       " 'forecast',\n",
       " 'destiel',\n",
       " 'circle',\n",
       " 'cosmopolitan',\n",
       " 'poydras',\n",
       " 'learning',\n",
       " 'maury',\n",
       " 'gripping',\n",
       " 'manira',\n",
       " 'giveaway',\n",
       " 'advice',\n",
       " 'poetry',\n",
       " 'answering',\n",
       " 'lay',\n",
       " 'iqgap',\n",
       " 'isla',\n",
       " 'rockall',\n",
       " 'infidel',\n",
       " 'karloff',\n",
       " 'clas',\n",
       " 'rifl',\n",
       " 'expelle',\n",
       " 'ajebo',\n",
       " 'shift',\n",
       " 'motarcycle',\n",
       " 'cullendu',\n",
       " 'megarust',\n",
       " 'purposely',\n",
       " 'flex',\n",
       " 'ptsd',\n",
       " 'egg',\n",
       " 'dimmish',\n",
       " 'roxanne',\n",
       " 'chelgui',\n",
       " 'twitcher',\n",
       " 'inorder',\n",
       " 'federation',\n",
       " 'drift',\n",
       " 'ethekwini',\n",
       " 'bum',\n",
       " 'leap',\n",
       " 'intensely',\n",
       " 'motivate',\n",
       " 'hangar',\n",
       " 'swede',\n",
       " 'ambient',\n",
       " 'thrush',\n",
       " 'seoul',\n",
       " 'navigator',\n",
       " 'table',\n",
       " 'funeral',\n",
       " 'reduce',\n",
       " 'staying',\n",
       " 'makgakga',\n",
       " 'misunderstand',\n",
       " 'handsom',\n",
       " 'perhaps',\n",
       " 'whatsapp',\n",
       " 'groesbeck',\n",
       " 'singh',\n",
       " 'himejima',\n",
       " 'preston',\n",
       " 'kalb',\n",
       " 'appeasement',\n",
       " 'nanterre',\n",
       " 'atlas',\n",
       " 'surigao',\n",
       " 'confrontation',\n",
       " 'estimate',\n",
       " 'style',\n",
       " 'bratty',\n",
       " 'encouraging',\n",
       " 'multifederal',\n",
       " 'phantom',\n",
       " 'morrissey',\n",
       " 'saddest',\n",
       " 'morning',\n",
       " 'tent',\n",
       " 'beast',\n",
       " 'romania',\n",
       " 'davao',\n",
       " 'cancer',\n",
       " 'unreal',\n",
       " 'dance',\n",
       " 'perspective',\n",
       " 'grab',\n",
       " 'rupert',\n",
       " 'boarder',\n",
       " 'maze',\n",
       " 'laundry',\n",
       " 'cruelty',\n",
       " 'disability',\n",
       " 'jgys',\n",
       " 'headache',\n",
       " 'mimi',\n",
       " 'reader',\n",
       " 'mouse',\n",
       " 'antarctic',\n",
       " 'justthe',\n",
       " 'casua',\n",
       " 'copaganda',\n",
       " 'observe',\n",
       " 'dragon',\n",
       " 'diversity',\n",
       " 'ebola',\n",
       " 'evaluation',\n",
       " 'proximity',\n",
       " 'kashmiri',\n",
       " 'fkhr',\n",
       " 'ofws',\n",
       " 'island',\n",
       " 'hogue',\n",
       " 'wide',\n",
       " 'phaselock',\n",
       " 'wary',\n",
       " 'distantly',\n",
       " 'assume',\n",
       " 'range',\n",
       " 'melanin',\n",
       " 'bure',\n",
       " 'aircrewman',\n",
       " 'danger',\n",
       " 'sella',\n",
       " 'aisle',\n",
       " 'teddy',\n",
       " 'time',\n",
       " 'pretend',\n",
       " 'medication',\n",
       " 'noello',\n",
       " 'manhattan',\n",
       " 'predict',\n",
       " 'improvement',\n",
       " 'whatever',\n",
       " 'akatsuki',\n",
       " 'masked',\n",
       " 'quit',\n",
       " 'siap',\n",
       " 'avoidant',\n",
       " 'sane',\n",
       " 'somet',\n",
       " 'hatin',\n",
       " 'instantly',\n",
       " 'mendy',\n",
       " 'amebo',\n",
       " 'gopher',\n",
       " 'simply',\n",
       " 'benefited',\n",
       " 'maternity',\n",
       " 'wrist',\n",
       " 'cricket',\n",
       " 'ushaka',\n",
       " 'erickson',\n",
       " 'fortune',\n",
       " 'askies',\n",
       " 'tories',\n",
       " 'paddocks',\n",
       " 'tunnel',\n",
       " 'accessor',\n",
       " 'transwellnesscenter',\n",
       " 'gilbert',\n",
       " 'heritage',\n",
       " 'resurgent',\n",
       " 'hittin',\n",
       " 'shyaka',\n",
       " 'gathering',\n",
       " 'updf',\n",
       " 'sickness',\n",
       " 'patio',\n",
       " 'luhnow',\n",
       " 'secular',\n",
       " 'yuck',\n",
       " 'bagratunyats',\n",
       " 'hisbah',\n",
       " 'eiceland',\n",
       " 'chamoru',\n",
       " 'notts',\n",
       " ...}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary_tokens(text):\n",
    "    \"\"\"function for converting whole text to vocabulary\"\"\"    \n",
    "    vocabulary  = set()\n",
    "    for text in lemmatized_text:\n",
    "        for word in text.split():\n",
    "            vocabulary.add(word)\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
